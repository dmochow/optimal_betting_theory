{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom function definitions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def get_conditional_cdf(df, key_cond, val_cond, key_metric, lb=-40, ub=40, n_points=4000, gaussian_bw=2, do_boot=False):\n",
    "\n",
    "    if do_boot:\n",
    "        data = df.loc[ df[key_cond] == val_cond, key_metric].sample(frac=1, replace=True)\n",
    "    else:\n",
    "        data = df.loc[ df[key_cond] == val_cond, key_metric]\n",
    "\n",
    "    sample = np.atleast_2d(data).T\n",
    "    kde = KernelDensity(kernel=\"gaussian\", bandwidth=gaussian_bw).fit(sample)\n",
    "    xx = np.atleast_2d(np.linspace(lb,ub,n_points)).T\n",
    "    yy = kde.score_samples(xx)\n",
    "    kde_cdf = np.cumsum(np.exp(yy)) / np.sum(np.exp(yy))\n",
    "\n",
    "    return kde_cdf, xx, yy, sample\n",
    "\n",
    "def get_quantiles_from_cdf(cdf,xx,yq):\n",
    "    # xx is the entire cdf x axis\n",
    "    # yq is a list of the quantiles that you want eg. [0.47,0.5,0.53]\n",
    "    vals=[]\n",
    "    inds=[]\n",
    "    for q in yq:\n",
    "        idx = np.argmin(np.abs(cdf-q))\n",
    "        vals.append(xx[idx])\n",
    "        inds.append(idx)\n",
    "    return vals, inds\n",
    "\n",
    "def my_ci(x):\n",
    "    # return 95% confidence interval of vector x\n",
    "    # x has been loaded with bootstrapped values, for example\n",
    "    return (np.quantile(x,0.025), np.quantile(x,0.975))\n",
    "\n",
    "def stylize_axes(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Specify the options of the analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "n_boots=100 # number of bootstrap resamples -- large values will slow down execution\n",
    "## Note 1: the figures in the paper use n_boots=1000 (setting to 100 here to make things run faster)\n",
    "## Note 2: due to the randomness in bootstrap resampling, the results are stochastic\n",
    "offsets = [-3,-2,-1,0,1,2,3] # hypothetical deviations from true median\n",
    "mincount=100 # minimum number of games in each stratification required to be retained for analysis\n",
    "gaussian_bw=2 # bandwidth parameter in kernel density estimation (used to deal with discreteness of margin)\n",
    "phi=100/110 # nominal profit on a unit bet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read the curated data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "dfo = pd.read_csv('../data/nfl_data.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the set of unique point spreads and point totals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "unq_spreads = np.unique(dfo.sportsbook_spread)\n",
    "unq_totals = np.unique(dfo.sportsbook_total)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build dataframes for analysis of margin of victory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "kde_ev=np.nan * np.ones(shape=(len(unq_spreads),n_boots,len(offsets)))\n",
    "dict_margin = [] # stores summary statistics: median + other quantiles\n",
    "dict_margin_raw = [] # stores each record on its own dataframe row\n",
    "\n",
    "for idx_s, spread in enumerate(unq_spreads):\n",
    "\n",
    "    for b in range(n_boots):\n",
    "        kde_cdf, xx, yy, sample = get_conditional_cdf(dfo,'sportsbook_spread',spread,'true_margin',-40,40,4000,gaussian_bw, do_boot=True)\n",
    "\n",
    "        tvals,tinds = get_quantiles_from_cdf(kde_cdf,xx,[phi/(1+phi),0.5,1/(1+phi)])\n",
    "\n",
    "        # measure expected value as a function of offset\n",
    "        # now across bootstrap samples\n",
    "        for idx_o,offset in enumerate(offsets):\n",
    "            tidx = np.argmin(np.abs(xx - (xx[tinds[1]] + offset)))\n",
    "            Fmm = kde_cdf[tidx]\n",
    "            ev_bh = Fmm*phi - (1-Fmm)\n",
    "            ev_bv = (1-Fmm)*phi - Fmm\n",
    "            ev_max = np.max((ev_bh,ev_bv))\n",
    "            kde_ev[idx_s,b,idx_o] = ev_max\n",
    "\n",
    "            dict_margin_raw.append(\n",
    "            {\n",
    "                'idx_offset':tidx,\n",
    "                'offset': offset,\n",
    "                'bootidx': b,\n",
    "                'spread': spread,\n",
    "                'ev': ev_max\n",
    "            }\n",
    "            )\n",
    "\n",
    "        dict_margin.append(\n",
    "            {\n",
    "                'q47': tvals[0][0],\n",
    "                'median': tvals[1][0],\n",
    "                'q53': tvals[2][0],\n",
    "                'count': np.sum(dfo['sportsbook_spread']==spread),\n",
    "                'spread': spread,\n",
    "                'ev': kde_ev[idx_s,b,:],\n",
    "                'bootidx': b\n",
    "            }\n",
    "        )\n",
    "\n",
    "df_margin = pd.DataFrame(dict_margin)\n",
    "df_margin=df_margin.set_index('spread')\n",
    "\n",
    "df_margin_raw = pd.DataFrame(dict_margin_raw)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split expected value into separate columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "df_tmp = df_margin.ev.apply(pd.Series)\n",
    "df_tmp.columns = ['-3','-2','-1','0','1','2','3']\n",
    "df_margin=pd.concat((df_margin,df_tmp),axis=1)\n",
    "df_margin=df_margin.drop('ev',axis=1)\n",
    "\n",
    "for key,val in df_margin.items():\n",
    "        try:\n",
    "            df_margin[key]=df_margin[key].str[0]\n",
    "        except:\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build dataframe for analysis of point totals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kde_total_ev=np.nan * np.ones(shape=(len(unq_totals),n_boots,len(offsets)))\n",
    "dict_total = []\n",
    "dict_total_raw = []\n",
    "\n",
    "for idx_t, total in enumerate(unq_totals):\n",
    "\n",
    "    for b in range(n_boots):\n",
    "        kde_cdf, xx, yy, _ = get_conditional_cdf(dfo,'sportsbook_total',total,'true_total',10,90,4000,gaussian_bw, do_boot=True)\n",
    "        tvals,tinds = get_quantiles_from_cdf(kde_cdf,xx,[0.47,0.5,0.53])\n",
    "\n",
    "        for idx_o,offset in enumerate(offsets):\n",
    "            tidx = np.argmin(np.abs(xx - (xx[tinds[1]] + offset)))\n",
    "            Fmm = kde_cdf[tidx]\n",
    "            ev_bo = Fmm*phi - (1-Fmm)\n",
    "            ev_bu = (1-Fmm)*phi - Fmm\n",
    "            ev_max = np.max((ev_bo,ev_bu))\n",
    "            kde_total_ev[idx_t,b,idx_o] = ev_max\n",
    "\n",
    "            dict_total_raw.append(\n",
    "            {\n",
    "                'idx_offset':tidx,\n",
    "                'offset': offset,\n",
    "                'bootidx': b,\n",
    "                'total': total,\n",
    "                'ev': ev_max\n",
    "            }\n",
    "            )\n",
    "\n",
    "        dict_total.append(\n",
    "            {\n",
    "                'q47': tvals[0],\n",
    "                'median': tvals[1],\n",
    "                'q53': tvals[2],\n",
    "                'count': np.sum(dfo['sportsbook_total']==total),\n",
    "                'total': total,\n",
    "                'ev': kde_total_ev[idx_t,b,:],\n",
    "                'bootidx': b\n",
    "            }\n",
    "        )\n",
    "df_total = pd.DataFrame(dict_total)\n",
    "df_total = df_total.set_index('total')\n",
    "\n",
    "df_total_raw = pd.DataFrame(dict_total_raw)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Repeat splitting of expected value for totals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_tmp = df_total.ev.apply(pd.Series)\n",
    "df_tmp.columns = ['-3','-2','-1','0','1','2','3']\n",
    "df_total=pd.concat((df_total,df_tmp),axis=1)\n",
    "df_total = df_total.drop('ev',axis=1)\n",
    "\n",
    "for key,val in df_total.items():\n",
    "    try:\n",
    "        df_total[key]=df_total[key].str[0]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "total_rows_to_show= (df_total['count']>mincount)\n",
    "total_n_to_show=np.sum(total_rows_to_show)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Identify which stratifications have enough games"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "has_enough_samples_margin = df_margin['count']>mincount\n",
    "valid_spreads = np.unique(df_margin[has_enough_samples_margin].index)\n",
    "\n",
    "has_enough_samples_total = df_total['count']>mincount\n",
    "valid_totals = np.unique(df_total[has_enough_samples_total].index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Construct 95\\% confidence intervals for margin of victory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_margin_ci = df_margin.loc[:,['q47','median','q53','-3','-2','-1','0','1','2','3']].groupby('spread').quantile((0.025,0.975))\n",
    "df_margin_ci = df_margin_ci.loc[valid_spreads,:]\n",
    "df_margin_ci['is_below_47'] = df_margin_ci.apply(lambda x: x['q47'] > x.name[0] if x.name[1]==0.025 else False, axis=1 )\n",
    "df_margin_ci['is_above_53'] = df_margin_ci.apply(lambda x: x['q53'] < x.name[0] if x.name[1]==0.975 else False, axis=1 )\n",
    "df_margin_ci['is_sig'] = df_margin_ci['is_below_47'] | df_margin_ci['is_above_53']\n",
    "\n",
    "df_margin_ci_lo = df_margin_ci.loc[df_margin_ci.index.get_level_values(None) == 0.025,:]\n",
    "df_margin_ci_hi = df_margin_ci.loc[df_margin_ci.index.get_level_values(None) == 0.975,:]\n",
    "\n",
    "ci_width_47_m = df_margin_ci.loc[df_margin_ci.index.get_level_values(None) == 0.975,'q47'].to_numpy() - df_margin_ci.loc[df_margin_ci.index.get_level_values(None) == 0.025,'q47'].to_numpy()\n",
    "\n",
    "ci_width_53_m = df_margin_ci.loc[df_margin_ci.index.get_level_values(None) == 0.975,'q53'].to_numpy() - df_margin_ci.loc[df_margin_ci.index.get_level_values(None) == 0.025,'q53'].to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Construct 95\\% confidence intervals for point totals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_total_ci = df_total.loc[:, ['q47', 'median', 'q53', '-3', '-2', '-1', '0', '1', '2', '3']].groupby('total').quantile(\n",
    "    (0.025, 0.975))\n",
    "df_total_ci = df_total_ci.loc[valid_totals, :]\n",
    "df_total_ci['is_below_47'] = df_total_ci.apply(lambda x: x['q47'] > x.name[0] if x.name[1] == 0.025 else False, axis=1)\n",
    "df_total_ci['is_above_53'] = df_total_ci.apply(lambda x: x['q53'] < x.name[0] if x.name[1] == 0.975 else False, axis=1)\n",
    "\n",
    "df_total_ci['is_sig'] = df_total_ci['is_below_47'] | df_total_ci['is_above_53']\n",
    "df_total_ci_lo = df_total_ci.loc[df_total_ci.index.get_level_values(None) == 0.025, :]\n",
    "df_total_ci_hi = df_total_ci.loc[df_total_ci.index.get_level_values(None) == 0.975, :]\n",
    "\n",
    "ci_width_47_t = df_total_ci.loc[df_total_ci.index.get_level_values(None) == 0.975, 'q47'].to_numpy() - df_total_ci.loc[\n",
    "    df_total_ci.index.get_level_values(None) == 0.025, 'q47'].to_numpy()\n",
    "\n",
    "ci_width_53_t = df_total_ci.loc[df_total_ci.index.get_level_values(None) == 0.975, 'q53'].to_numpy() - df_total_ci.loc[\n",
    "    df_total_ci.index.get_level_values(None) == 0.025, 'q53'].to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regress sportsbook point spread onto empirical median margin of victory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_margin = df_margin.reset_index()\n",
    "\n",
    "df_group = df_margin[df_margin.spread.isin(valid_spreads)].groupby('bootidx')['spread', 'median']\n",
    "df_margin_reg = pd.DataFrame()\n",
    "for group in df_group.groups.keys():\n",
    "    df = df_group.get_group(group)\n",
    "    X = np.array(df[['spread']])\n",
    "    y = np.array(df[['median']])\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    df_margin_reg.loc[group, ['slope']] = model.coef_[0][0]\n",
    "    df_margin_reg.loc[group, ['intercept']] = model.intercept_[0]\n",
    "    df_margin_reg.loc[group, ['r2']] = model.score(X, y)\n",
    "\n",
    "df_margin_reg_mean = df_margin_reg.mean(axis=0)\n",
    "df_margin_reg_lo = df_margin_reg.quantile(0.025)\n",
    "df_margin_reg_hi = df_margin_reg.quantile(0.975)\n",
    "\n",
    "a_m = df_margin_reg_mean['slope']\n",
    "b_m = df_margin_reg_mean['intercept']\n",
    "r_squared_m = df_margin_reg_mean['r2']\n",
    "\n",
    "df_margin=df_margin.set_index('spread')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regress sportsbook point total onto empirical median point total"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_total = df_total.reset_index()\n",
    "\n",
    "df_group = df_total[df_total.total.isin(valid_totals)].groupby('bootidx')['total', 'median']\n",
    "df_total_reg = pd.DataFrame()\n",
    "for group in df_group.groups.keys():\n",
    "    df = df_group.get_group(group)\n",
    "    X = np.array(df[['total']])\n",
    "    y = np.array(df[['median']])\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    df_total_reg.loc[group, ['slope']] = model.coef_[0][0]\n",
    "    df_total_reg.loc[group, ['intercept']] = model.intercept_[0]\n",
    "    df_total_reg.loc[group, ['r2']] = model.score(X, y)\n",
    "\n",
    "df_total_reg_mean = df_total_reg.mean(axis=0)\n",
    "df_total_reg_lo = df_total_reg.quantile(0.025)\n",
    "df_total_reg_hi = df_total_reg.quantile(0.975)\n",
    "\n",
    "a_t = df_total_reg_mean['slope']\n",
    "b_t = df_total_reg_mean['intercept']\n",
    "r_squared_t = df_total_reg_mean['r2']\n",
    "\n",
    "a_t, b_t, r_squared_t\n",
    "\n",
    "df_total = df_total.set_index('total')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute mean values across _bootstrap resamples_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_margin_mu = df_margin.loc[valid_spreads,['q47','median','q53','-3','-2','-1','0','1','2','3']].groupby('spread').mean()\n",
    "df_total_mu = df_total.loc[valid_totals,['q47','median','q53','-3','-2','-1','0','1','2','3']].groupby('total').mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Combine mean values with confidence intervals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_margin_mu['level'] = 'Mean'\n",
    "df_margin_mu.set_index('level', append=True, inplace=True)\n",
    "df_margin_cat = pd.concat((df_margin_mu, df_margin_ci), axis=0)\n",
    "df_margin_cat = df_margin_cat.sort_index()\n",
    "\n",
    "df_total_mu['level'] = 'Mean'\n",
    "df_total_mu.set_index('level', append=True, inplace=True)\n",
    "df_total_cat = pd.concat((df_total_mu, df_total_ci), axis=0)\n",
    "df_total_cat = df_total_cat.sort_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute grand means (relevant for expected values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grand_mus_margin = df_margin_mu.mean(axis=0)\n",
    "grand_sigmas_margin = df_margin_mu.std(axis=0)\n",
    "\n",
    "grand_mus_total = df_total_mu.mean(axis=0)\n",
    "grand_sigmas_total = df_total_mu.std(axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make a copy of dataframe that only contains the stratifications with enough samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_margin_raw_filt = df_margin_raw.loc[df_margin_raw.spread.isin(valid_spreads),:]\n",
    "df_total_raw_filt = df_total_raw.loc[df_total_raw.total.isin(valid_totals),:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Figure 1\n",
    "## Compare sportsbook against empirical median"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# data for kde plot of one stratified sample of margins (here so=6)\n",
    "so=6\n",
    "mdnm=df_margin_mu.loc[so,'median'].to_numpy()[0]\n",
    "kde_cdfm, xxm, yym, smpm = get_conditional_cdf(dfo,'sportsbook_spread',so,'true_margin',-50,50,5000,gaussian_bw)\n",
    "\n",
    "# data for kde plot of one stratified sample of totals\n",
    "to=46\n",
    "mdnt=df_total_mu.loc[to,'median'].to_numpy()[0]\n",
    "kde_cdft, xxt, yyt, smpt = get_conditional_cdf(dfo,'sportsbook_total',to,'true_total',10,90,5000,gaussian_bw)\n",
    "\n",
    "lgfs=12\n",
    "\n",
    "fig,ax = plt.subplots(2,2,figsize=(12,9))\n",
    "ax[0,0].plot(xxm,np.exp(yym),color='lightsteelblue')\n",
    "ax[0,0].hist(smpm,bins=25,density=True,range=[-50,50],fc=(255/255,165/255,0/255,0.25))\n",
    "#fc=(255/255,87/255,51/255,0.25)\n",
    "yl=ax[0,0].get_ylim()\n",
    "ax[0,0].plot([mdnm, mdnm],yl, label='median margin', ls='--')\n",
    "ax[0,0].plot([so, so],yl, label='sportsbook spread', ls='--')\n",
    "ax[0,0].legend(loc='upper right',fontsize=lgfs)\n",
    "ax[0,0].set_ylim(yl)\n",
    "ax[0,0].set_ylabel('Prob. Density', fontdict={'family':'sans-serif','size':18})\n",
    "ax[0,0].set_xlabel('Margin of victory', fontdict={'family':'sans-serif','size':18})\n",
    "ax[0,0].text(-53, 0.025, '$\\overline{m} = $' + \"{:.2f}\".format(mdnm)  , fontsize = 14)\n",
    "ax[0,0].text(-53, 0.03, 'spread = ' + \"{:.0f}\".format(so), fontsize = 14)\n",
    "ax[0,0].text(-53, 0.02, '95% CI [' + \"{:.2f}\".format(df_margin_ci.loc[(so,0.025),'median'])\n",
    "             + \", {:.2f}\".format(df_margin_ci.loc[(so,0.975),'median']) + ']', fontsize = 14)\n",
    "ax[0,0].text(-70,0.037,'a', fontdict={'family':'sans-serif','size':20,'weight':'bold'} )\n",
    "\n",
    "ax[0,1].plot(xxt,np.exp(yyt),color='lightsteelblue')\n",
    "ax[0,1].hist(smpt,bins=25,density=True,range=[10,90],fc=(255/255,165/255,0/255,0.25))\n",
    "yl=ax[0,1].get_ylim()\n",
    "ax[0,1].plot([mdnt, mdnt],yl, label='median total', ls='--')\n",
    "ax[0,1].plot([to, to],yl, label='sportsbook total', ls='--')\n",
    "ax[0,1].legend(loc='upper right', fontsize=lgfs)\n",
    "ax[0,1].set_ylim(yl)\n",
    "ax[0,1].set_xlim((0,100))\n",
    "#ax[0,1].set_ylabel('Prob. Density', fontdict={'family':'sans-serif','size':18})\n",
    "ax[0,1].set_xlabel('Point total', fontdict={'family':'sans-serif','size':18})\n",
    "ax[0,1].text(62, 0.025, r'total = ' + \"{:.0f}\".format(to), fontsize = 14)\n",
    "ax[0,1].text(62, 0.02, '$\\overline{t} = $' + \"{:.2f}\".format(mdnt)  , fontsize = 14)\n",
    "ax[0,1].text(62, 0.015, '95% CI [' + \"{:.2f}\".format(df_total_ci.loc[(to,0.025),'median'])\n",
    "             + \", {:.2f}\".format(df_total_ci.loc[(to,0.975),'median']) + ']', fontsize = 14)\n",
    "ax[0,1].text(-11.5,0.0375,'b', fontdict={'family':'sans-serif','size':20,'weight':'bold'} )\n",
    "\n",
    "\n",
    "ax[1,0].plot(valid_spreads,df_margin_mu['median'],'o',color='steelblue')\n",
    "xax = np.array(ax[1,0].get_xlim())\n",
    "ax[1,0].plot(xax, a_m*xax+b_m,'--',color='steelblue', label='best fit')\n",
    "ax[1,0].plot(xax, xax,'--',color='dimgray', label='$\\overline{m}=s$')\n",
    "stylize_axes(ax[1,0])\n",
    "ax[1,0].set_ylabel('Median margin of victory', fontdict={'family':'sans-serif','size':18})\n",
    "ax[1,0].set_xlabel('Sportsbook spread', fontdict={'family':'sans-serif','size':18})\n",
    "ax[1,0].text(-7, 10, '$\\overline{m} = $' + \"{:.2f}\".format(a_m) + \"$\\cdot s$  - {:.2f}\".format(np.abs(b_m))  , fontsize = 14)\n",
    "\n",
    "ax[1,0].text(-7, 8.5, 'slope 95% CI [' + \"{:.2f}\".format(df_margin_reg_lo['slope'] )\n",
    "             + \", {:.2f}\".format(df_margin_reg_hi['slope']) + ']', fontsize = 14)\n",
    "ax[1,0].text(-7, 7, 'intercept 95% CI [' + \"{:.2f}\".format(df_margin_reg_lo['intercept'] )\n",
    "             + \", {:.2f}\".format(df_margin_reg_hi['intercept']) + ']', fontsize = 14)\n",
    "\n",
    "ax[1,0].text(-7, 5, '$r^2 = $' + \"{:.2f}\".format(r_squared_m), fontsize = 14)\n",
    "\n",
    "ax[1,0].legend(loc='lower right',fontsize=lgfs)\n",
    "ax[1,0].text(-11.5,12,'c', fontdict={'family':'sans-serif','size':20,'weight':'bold'} )\n",
    "\n",
    "ax[1,1].plot(valid_totals,df_total_mu['median'],'o',color='steelblue')\n",
    "xax = np.array(ax[1,1].get_xlim())\n",
    "ax[1,1].plot(xax, a_t*xax+b_t,'--',color='steelblue', label='best fit')\n",
    "ax[1,1].plot(xax, xax,'--',color='dimgray', label='$\\overline{t}= $' +  r'$\\tau$')\n",
    "stylize_axes(ax[1,1])\n",
    "ax[1,1].set_ylabel('Median total', fontdict={'family':'sans-serif','size':18})\n",
    "ax[1,1].set_xlabel('Sportsbook total', fontdict={'family':'sans-serif','size':18})\n",
    "ax[1,1].text(36, 48, '$\\overline{t} = $' + \"{:.2f}\".format(a_t) + '$\\cdot$' + r'$\\tau + $' + \"{:.2f}\".format(np.abs(b_t))  , fontsize = 14)\n",
    "\n",
    "ax[1,1].text(36, 46.5, 'slope 95% CI [' + \"{:.2f}\".format(df_total_reg_lo['slope'] )\n",
    "             + \", {:.2f}\".format(df_total_reg_hi['slope']) + ']', fontsize = 14)\n",
    "ax[1,1].text(36, 45, 'intercept 95% CI [' + \"{:.2f}\".format(df_total_reg_lo['intercept'] )\n",
    "             + \", {:.2f}\".format(df_total_reg_hi['intercept']) + ']', fontsize = 14)\n",
    "\n",
    "ax[1,1].text(36, 43.5, '$r^2 = $' + \"{:.2f}\".format(r_squared_t), fontsize = 14)\n",
    "ax[1,1].legend(loc='lower right',fontsize=lgfs)\n",
    "ax[1,1].text(34.25,50.5,'d', fontdict={'family':'sans-serif','size':20,'weight':'bold'} )\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Figure 2\n",
    "## Sportsbook point spread versus empirical margin of victory, shown for each stratification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,figsize=(10,6))\n",
    "\n",
    "xticks = np.arange(len(valid_spreads))\n",
    "xticklabels = valid_spreads\n",
    "\n",
    "# show 95% CI for 47th percentile (percentiles of percentiles!)\n",
    "hb_47=ax.barh(xticks, ci_width_47_m, left=df_margin_ci_lo['q47'], color='darkgrey', label='95% CI of 0.476 quantile', alpha=0.5)\n",
    "hb_53=ax.barh(xticks, ci_width_53_m, left=df_margin_ci_lo['q53'], color='slategrey', label='95% CI of 0.524 quantile', alpha=0.5)\n",
    "hp=ax.plot(valid_spreads,xticks,'o', label='Sportsbook spread', color='darkorange')\n",
    "xtck=ax.get_xticks()\n",
    "ax.set_yticks(xticks)\n",
    "ax.set_yticklabels(xticklabels)\n",
    "stylize_axes(ax)\n",
    "ax.set_ylabel('Sportsbook spread', fontdict={'family':'sans-serif','size':18})\n",
    "ax.set_xlabel('Margin of Victory', fontdict={'family':'sans-serif','size':18})\n",
    "ax.legend(fontsize=lgfs)\n",
    "\n",
    "plt.show()\n",
    "fig.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Figure 3\n",
    "## Sportsbook point total versus empirical total, shown for each stratification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,figsize=(10,6))\n",
    "\n",
    "xticks = np.arange(len(valid_totals))\n",
    "xticklabels = valid_totals\n",
    "\n",
    "# show 95% CI for 47th percentile (percentiles of percentiles!)\n",
    "hb_47=ax.barh(xticks, ci_width_47_t, left=df_total_ci_lo['q47'], color='darkgrey', label='95% CI of 0.476 quantile', alpha=0.5)\n",
    "hb_53=ax.barh(xticks, ci_width_53_t, left=df_total_ci_lo['q53'], color='slategrey', label='95% CI of 0.524 quantile', alpha=0.5)\n",
    "hp=ax.plot(valid_totals,xticks,'o', label='Sportsbook total', color='darkorange')\n",
    "xtck=ax.get_xticks()\n",
    "ax.set_yticks(xticks)\n",
    "ax.set_yticklabels(xticklabels)\n",
    "stylize_axes(ax)\n",
    "ax.set_ylabel('Sportsbook total', fontdict={'family':'sans-serif','size':18})\n",
    "ax.set_xlabel('Point total', fontdict={'family':'sans-serif','size':18})\n",
    "ax.legend(fontsize=lgfs)\n",
    "#ax.text(-10.5,19.5,'a', fontdict={'family':'sans-serif','size':20,'weight':'bold'} )\n",
    "\n",
    "plt.show()\n",
    "fig.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Figure 4\n",
    "## Expected profit as a function of sportsbook error in setting point spread"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,figsize=(10,6))\n",
    "ax=sns.barplot(data=df_margin_raw_filt, x=\"offset\", y=\"ev\", hue=\"spread\", hue_order=[-3,2.5,3,7], errorbar=my_ci, palette=\"muted\")\n",
    "\n",
    "ax.set_xlabel('Bias in sportsbook spread', fontdict={'family':'sans-serif','size':18})\n",
    "ax.set_ylabel('Expected profit on unit bet', fontdict={'family':'sans-serif','size':18})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Figure 5\n",
    "## Expected profit as a function of sportsbook error in setting point total"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,figsize=(10,6))\n",
    "\n",
    "ax=sns.barplot(data=df_total_raw_filt, x=\"offset\", y=\"ev\", hue=\"total\", hue_order=[41,43,44,45], errorbar=my_ci, palette=\"muted\")\n",
    "\n",
    "ax.set_xlabel('Bias in sportsbook total', fontdict={'family':'sans-serif','size':18})\n",
    "ax.set_ylabel('Expected profit on unit bet', fontdict={'family':'sans-serif','size':18})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
